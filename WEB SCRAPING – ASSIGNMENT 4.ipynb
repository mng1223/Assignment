{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cf6aa629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (4.15.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anaconda3\\anaconda_new\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f4e208ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries at once\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b11da0f",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e078c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "830bc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "date=[]\n",
    "views=[]\n",
    "for i in range(1,31):\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr/td[1]\".format(k)):\n",
    "            rank.append(i.text)\n",
    "    except NoSuchAttributeException as e:\n",
    "        rank.append('--')\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr/td[2]\".format(k)):\n",
    "            name.append(i.text)\n",
    "    except NoSuchAttributeException as e:\n",
    "        name.append('--')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr/td[3]\".format(k)):\n",
    "            artist.append(i.text)\n",
    "    except NoSuchAttributeException as e:\n",
    "        artist.append('--')\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr/td[4]\".format(k)):\n",
    "            views.append(i.text)\n",
    "    except NoSuchAttributeException as e:\n",
    "        views.append('--')\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,\"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr/td[5]\".format(k)):\n",
    "            date.append(i.text)\n",
    "    except NoSuchAttributeException as e:\n",
    "        date.append('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e2473413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "900\n",
      "900\n",
      "900\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "print(len(rank))\n",
    "print(len(name))\n",
    "print(len(artist))\n",
    "print(len(date))\n",
    "print(len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "778d88bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[52]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                             \"Lakdi Ki Kathi\"[44]   \n",
       "20  21.                                      \"Sorry\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.          \"Humpty the train on a fruits ride\"[47]   \n",
       "23  24.                                 \"Dark Horse\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                      \"Shree Hanuman Chalisa\"[52]   \n",
       "28  29.                             \"Girls Like You\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                       Jingle Toons      June 14, 2018   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Katy Perry  February 20, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                          Passenger      July 25, 2012   \n",
       "26                                        Alan Walker   December 3, 2015   \n",
       "27                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   13.65  \n",
       "1    8.32  \n",
       "2    6.84  \n",
       "3    6.50  \n",
       "4    6.14  \n",
       "5    6.09  \n",
       "6    5.71  \n",
       "7    5.57  \n",
       "8    5.09  \n",
       "9    5.01  \n",
       "10   4.96  \n",
       "11   4.57  \n",
       "12   4.48  \n",
       "13   4.16  \n",
       "14   3.97  \n",
       "15   3.92  \n",
       "16   3.91  \n",
       "17   3.84  \n",
       "18   3.78  \n",
       "19   3.76  \n",
       "20   3.74  \n",
       "21   3.69  \n",
       "22   3.63  \n",
       "23   3.63  \n",
       "24   3.60  \n",
       "25   3.56  \n",
       "26   3.55  \n",
       "27   3.54  \n",
       "28   3.52  \n",
       "29   3.50  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':rank[0:30],'Name':name[0:30],'Artist':artist[0:30],'Upload date':date[0:30],'Views':views[0:30]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f6962fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b944804",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "7b0f3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9832bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.bcci.tv'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8b0d61f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/header/div[3]/div[1]/ul/div[1]/a[2]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c4ce0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team=[]\n",
    "Date_Time =[]\n",
    "Ground=[]\n",
    "Test_ODI=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2de9b3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENGLAND A WOMENS TOUR OF INDIA T20 SERIES',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'ENGLAND A WOMENS TOUR OF INDIA T20 SERIES',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'ENGLAND WOMEN TOUR OF INDIA 2023-24',\n",
       " 'ENGLAND WOMEN TOUR OF INDIA 2023-24',\n",
       " 'ENGLAND WOMEN TOUR OF INDIA 2023-24',\n",
       " 'INDIA TOUR OF SOUTH AFRICA 2023-24',\n",
       " 'INDIA TOUR OF SOUTH AFRICA 2023-24']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME=[]\n",
    "name_tag=driver.find_elements(By.XPATH,'//*[@id=\"match-card\"]/div[1]/div/div/h5')\n",
    "\n",
    "for i in name_tag:\n",
    "    ntitle=i.text\n",
    "    NAME.append(ntitle)\n",
    "    \n",
    "NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "6fc0298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wankhede Stadium,',\n",
       " 'Shaheed Veer Narayan Singh International Cricket Stadium,',\n",
       " 'Wankhede Stadium,',\n",
       " 'M Chinnaswamy Stadium,',\n",
       " 'Wankhede Stadium,',\n",
       " 'Wankhede Stadium,',\n",
       " 'Wankhede Stadium,',\n",
       " 'Kingsmead,',\n",
       " \"St George's Park,\"]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PLACE=[]\n",
    "place_tag=driver.find_elements(By.XPATH,'//*[@id=\"match-card\"]/div[2]/div[1]/span[1]')\n",
    "for i in place_tag:\n",
    "    ptitle=i.text\n",
    "    PLACE.append(ptitle)\n",
    "    \n",
    "PLACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "8995858a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 DECEMBER, 2023',\n",
       " '1 DECEMBER, 2023',\n",
       " '3 DECEMBER, 2023',\n",
       " '3 DECEMBER, 2023',\n",
       " '6 DECEMBER, 2023',\n",
       " '9 DECEMBER, 2023',\n",
       " '10 DECEMBER, 2023',\n",
       " '10 DECEMBER, 2023',\n",
       " '12 DECEMBER, 2023']"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape All Date tag\n",
    "\n",
    "DATE=[]\n",
    "date_tag=driver.find_elements(By.XPATH,'//*[@id=\"match-card\"]/div[1]/div/div/div[2]/div[1]')\n",
    "for i in date_tag:\n",
    "    date=i.text\n",
    "    DATE.append(date)\n",
    "DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "1fe5ac7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '1:30 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '7:00 PM IST',\n",
       " '9:30 PM IST',\n",
       " '9:30 PM IST']"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape All Time tag\n",
    "\n",
    "TIME=[]\n",
    "time_tag=driver.find_elements(By.XPATH,'//*[@id=\"match-card\"]/div[1]/div/div/div[2]/div[2]')\n",
    "for i in time_tag:\n",
    "    timetag=i.text\n",
    "    TIME.append(timetag)\n",
    "TIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c05bc639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>Shaheed Veer Narayan Singh International Crick...</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>6 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>9 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>Kingsmead,</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>12 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Name  \\\n",
       "0  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "1            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "2  ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "3            AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "4        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "5        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "6        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "7         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "8         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "\n",
       "                                               Place               Date  \\\n",
       "0                                  Wankhede Stadium,   1 DECEMBER, 2023   \n",
       "1  Shaheed Veer Narayan Singh International Crick...   1 DECEMBER, 2023   \n",
       "2                                  Wankhede Stadium,   3 DECEMBER, 2023   \n",
       "3                             M Chinnaswamy Stadium,   3 DECEMBER, 2023   \n",
       "4                                  Wankhede Stadium,   6 DECEMBER, 2023   \n",
       "5                                  Wankhede Stadium,   9 DECEMBER, 2023   \n",
       "6                                  Wankhede Stadium,  10 DECEMBER, 2023   \n",
       "7                                         Kingsmead,  10 DECEMBER, 2023   \n",
       "8                                  St George's Park,  12 DECEMBER, 2023   \n",
       "\n",
       "          Time  \n",
       "0  1:30 PM IST  \n",
       "1  7:00 PM IST  \n",
       "2  1:30 PM IST  \n",
       "3  7:00 PM IST  \n",
       "4  7:00 PM IST  \n",
       "5  7:00 PM IST  \n",
       "6  7:00 PM IST  \n",
       "7  9:30 PM IST  \n",
       "8  9:30 PM IST  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fixtures=pd.DataFrame({})\n",
    "Fixtures['Name']=NAME\n",
    "Fixtures['Place']=PLACE\n",
    "Fixtures['Date']=DATE\n",
    "Fixtures['Time']=TIME\n",
    "Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f2ea9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcedf4b2",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dec76919",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0071b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1638bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## click on India \n",
    "india=driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\")\n",
    "driver.get(india.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ff06988",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Clicking on GDP of Indian State\n",
    "gdp=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98a52b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_19=[]\n",
    "GSDP_18=[]\n",
    "Share=[]\n",
    "GDP=[]\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[1]\"):\n",
    "    Rank.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[2]\"):\n",
    "    State.append(i.text)   \n",
    "for i in driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[3]\"):\n",
    "    GSDP_19.append(i.text)  \n",
    "for i in driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[8]\"):\n",
    "    GSDP_18.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[5]\"):\n",
    "    Share.append(i.text)   \n",
    "for i in driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[6]\"):\n",
    "    GDP.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64892236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 19-20</th>\n",
       "      <th>GSDP 18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP($Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>739,525</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>677,428</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>621,301</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>612,828</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>522,009</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>559,412</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>590,569</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>531,085</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>375,651</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>397,669</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>376,877</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>234,048</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>231,182</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>224,986</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>193,273</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>112,755</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>117,851</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>57,787</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>36,963</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>31,192</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>23,013</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>24,682</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>18,722</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>19,300</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>17,647</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>16,676</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>16,478</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 19-20 GSDP 18-19   Share GDP($Billion)\n",
       "0     1                Maharashtra          -  2,039,074  13.94%       399.921\n",
       "1     2                 Tamil Nadu  1,845,853  1,215,307   8.63%       247.629\n",
       "2     3              Uttar Pradesh  1,687,818  1,123,982   8.39%       240.726\n",
       "3     4                    Gujarat          -  1,186,379   7.96%       228.290\n",
       "4     5                  Karnataka  1,631,977  1,091,077   7.91%       226.806\n",
       "5     6                West Bengal  1,253,832    739,525   5.77%       165.556\n",
       "6     7                  Rajasthan  1,020,989    677,428   4.99%       143.179\n",
       "7     8             Andhra Pradesh    972,782    621,301   4.57%       131.083\n",
       "8     9                  Telangana    969,604    612,828   4.56%       130.791\n",
       "9    10             Madhya Pradesh    906,672    522,009   4.29%       122.977\n",
       "10   11                     Kerala          -    559,412   4.14%       118.733\n",
       "11   12                      Delhi    856,112    590,569   4.10%       117.703\n",
       "12   13                    Haryana    831,610    531,085   3.89%       111.519\n",
       "13   14                      Bihar    611,804    375,651   2.81%        80.562\n",
       "14   15                     Punjab    574,760    397,669   2.79%        79.957\n",
       "15   16                     Odisha    521,275    376,877   2.58%        74.098\n",
       "16   17                      Assam          -    234,048   1.67%        47.982\n",
       "17   18               Chhattisgarh    329,180    231,182   1.61%        46.187\n",
       "18   19                  Jharkhand    328,598    224,986   1.57%        45.145\n",
       "19   20                Uttarakhand          -    193,273   1.30%        37.351\n",
       "20   21            Jammu & Kashmir          -    112,755   0.83%        23.690\n",
       "21   22           Himachal Pradesh    165,472    117,851   0.81%        23.369\n",
       "22   23                        Goa     80,449     57,787   0.39%        11.115\n",
       "23   24                    Tripura     55,984     36,963   0.26%         7.571\n",
       "24   25                 Chandigarh          -     31,192   0.22%         6.397\n",
       "25   26                 Puducherry     38,253     23,013   0.18%         5.230\n",
       "26   27                  Meghalaya     36,572     24,682   0.18%         5.086\n",
       "27   28                     Sikkim     32,496     18,722   0.15%         4.363\n",
       "28   29                    Manipur     31,790     19,300   0.15%         4.233\n",
       "29   30                   Nagaland          -     17,647   0.14%         4.144\n",
       "30   31          Arunachal Pradesh          -     16,676   0.13%         3.737\n",
       "31   32                    Mizoram     26,503     16,478   0.12%         3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -       -             -"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'State':State,'GSDP 19-20':GSDP_19,'GSDP 18-19':GSDP_18,'Share':Share,'GDP($Billion)':GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4dcb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249c606",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6206657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04935520",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ece1bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Repository_Name =[]\n",
    "Language=[]\n",
    "Muted_Link=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd40a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')       # Locating page foe top videos by xpath\n",
    "explore.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b25d5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')       # Locating page foe top videos by xpath\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec357570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['LouisShark /', 'linexjlin /', 'OthersideAI /', 'opa334 /', 'nlohmann /', 'run-llama /', '1Panel-dev /', 'Vaibhavs10 /', 'grpc-ecosystem /', '521xueweihan /', 'googleapis /', 'Ftindy /', 'NVIDIA /', 'jason5ng32 /', 'florinpop17 /', 'gto76 /', 'makeplane /', 'atomone-hub /', 'pointfreeco /', 'fastlane /', 'StanGirard /', 'Azure /', 'brianvoe /', 'DrKLO /', 'Melledy /', 'LouisShark /', 'linexjlin /', 'OthersideAI /', 'opa334 /', 'nlohmann /', 'run-llama /', '1Panel-dev /', 'Vaibhavs10 /', 'grpc-ecosystem /', '521xueweihan /', 'googleapis /', 'Ftindy /', 'NVIDIA /', 'jason5ng32 /', 'florinpop17 /', 'gto76 /', 'makeplane /', 'atomone-hub /', 'pointfreeco /', 'fastlane /', 'StanGirard /', 'Azure /', 'brianvoe /', 'DrKLO /', 'Melledy /']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Repositor_Name \n",
    "RN=driver.find_elements(By.XPATH,\"//span[@class='text-normal']\")\n",
    "for i in RN:\n",
    "    if i.text is None :\n",
    "        Repository_Name.append(\"--\") \n",
    "    else:\n",
    "        Repository_Name.append(i.text)\n",
    "print(len(Repository_Name),Repository_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c56be9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 [\"store all agent's system prompt\", 'leaked prompts of GPTs', 'Jailed iOS app that can install IPAs permanently with arbitary entitlements and root helpers because it trolls Apple', 'JSON for Modern C++', 'Build ChatGPT over your data, all with natural language', '🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。', 'gRPC to JSON proxy generator following the gRPC HTTP spec', '分享 GitHub 上有趣、入门级的开源项目。Share interesting, entry-level open source projects on GitHub.', 'A PHP client library for accessing Google APIs', 'Ongoing research training transformer models at scale', 'IP Toolkit. It allows you to view local IP, IP information after using a proxy, check for DNS leaks, examine WebRTC connections, and test website availability. || IP 工具箱。可以查看本机IP、挂代理后的IP信息、检查 DNS 泄露、检查 WebRTC 连接、测试网站可用性等。', 'A Collection of application ideas which can be used to improve your coding skills.', 'Comprehensive Python Cheatsheet', '🔥 🔥 🔥 Open Source JIRA, Linear and Height Alternative. Plane helps you track your issues, epics, and product roadmaps in the simplest way possible.', 'declaration of genesis', 'A library for building applications in a consistent and understandable way, with composition, testing, and ergonomics in mind.', '🚀 The easiest way to automate building and releasing your iOS and Android apps', '🧠 Your supercharged Second Brain 🧠 Your personal productivity assistant to chat with your dumped files (PDF, CSV) & apps using GPT 3.5 / 4 turbo, Private, Anthropic, VertexAI, Ollama, LLMs, that you can share with users ! Local & Private alternative to OpenAI GPTs', 'Azure Quickstart Templates', 'Random fake data generator written in go', 'Telegram for Android source']\n"
     ]
    }
   ],
   "source": [
    "Description=[]\n",
    "#scraping the Description \n",
    "des=driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "for i in des:\n",
    "    if i.text is None :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)\n",
    "print(len(Description),Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8bd3800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 ['C', 'Python', 'C', 'C++', 'Python', 'Go', 'Jupyter Notebook', 'Go', 'Python', 'PHP', 'Python', 'JavaScript', 'Python', 'TypeScript', 'Swift', 'Ruby', 'TypeScript', 'Bicep', 'Go', 'Java', 'Java', 'C', 'Python', 'C', 'C++', 'Python', 'Go', 'Jupyter Notebook', 'Go', 'Python', 'PHP', 'Python', 'JavaScript', 'Python', 'TypeScript', 'Swift', 'Ruby', 'TypeScript', 'Bicep', 'Go', 'Java', 'Java']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Language \n",
    "L=driver.find_elements(By.XPATH,\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in L:\n",
    "    if i.text is None :\n",
    "        Language.append(\"NAN\") \n",
    "    else:\n",
    "        Language.append(i.text)\n",
    "print(len(Language),Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c01be6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 ['3,110', '549', '5,236', '1,017', '925', '77', '11,731', '744', '37,730', '6,384', '4,190', '459', '13,434', '1,386', '2,765', '174', '16,522', '2,112', '78,610', '9,443', '8,903', '3,655', '770', '119', '6,962', '1,542', '639', '85', '69,717', '8,955', '34,046', '6,239', '18,635', '853', '44', '16', '10,150', '1,122', '37,797', '5,653', '24,629', '2,684', '13,346', '15,902', '3,553', '257', '22,956', '7,682', '191', '55', '3,110', '549', '5,236', '1,017', '925', '77', '11,731', '744', '37,730', '6,384', '4,190', '459', '13,434', '1,386', '2,765', '174', '16,522', '2,112', '78,610', '9,443', '8,903', '3,655', '770', '119', '6,962', '1,542', '639', '85', '69,717', '8,955', '34,046', '6,239', '18,635', '853', '44', '16', '10,150', '1,122', '37,797', '5,653', '24,629', '2,684', '13,346', '15,902', '3,553', '257', '22,956', '7,682', '191', '55']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Muted_Link And Star \n",
    "ml=driver.find_elements(By.XPATH,\"//a[@class='Link Link--muted d-inline-block mr-3']\")\n",
    "for i in ml:\n",
    "    if i.text is None :\n",
    "        Muted_Link.append(\"NAN\") \n",
    "    else:\n",
    "        Muted_Link.append(i.text)\n",
    "print(len(Muted_Link),Muted_Link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59ee6241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['549', '1,017', '77', '744', '6,384', '459', '1,386', '174', '2,112', '9,443', '3,655', '119', '1,542', '85', '8,955', '6,239', '853', '16', '1,122', '5,653', '2,684', '15,902', '257', '7,682', '55', '549', '1,017', '77', '744', '6,384', '459', '1,386', '174', '2,112', '9,443', '3,655', '119', '1,542', '85', '8,955', '6,239', '853', '16', '1,122', '5,653', '2,684', '15,902', '257', '7,682', '55']\n"
     ]
    }
   ],
   "source": [
    "Muted=[]\n",
    "for i in range(1,len(Muted_Link),2):\n",
    "    Muted.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted),Muted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00e5c7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 ['3,110', '5,236', '925', '11,731', '37,730', '4,190', '13,434', '2,765', '16,522', '78,610', '8,903', '770', '6,962', '639', '69,717', '34,046', '18,635', '44', '10,150', '37,797', '24,629', '13,346', '3,553', '22,956', '191', '3,110', '5,236', '925', '11,731', '37,730', '4,190', '13,434', '2,765', '16,522', '78,610', '8,903', '770', '6,962', '639', '69,717', '34,046', '18,635', '44', '10,150', '37,797', '24,629', '13,346', '3,553', '22,956', '191']\n"
     ]
    }
   ],
   "source": [
    "Muted_Star=[]\n",
    "for i in range(0,len(Muted_Link),2):\n",
    "    Muted_Star.append(Muted_Link[i])\n",
    "    \n",
    "print(len(Muted_Star),Muted_Star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cc7cf382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language</th>\n",
       "      <th>Conutrybuted</th>\n",
       "      <th>Muted_Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LouisShark /</td>\n",
       "      <td>store all agent's system prompt</td>\n",
       "      <td>C</td>\n",
       "      <td>549</td>\n",
       "      <td>3,110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linexjlin /</td>\n",
       "      <td>leaked prompts of GPTs</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,017</td>\n",
       "      <td>5,236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OthersideAI /</td>\n",
       "      <td>Jailed iOS app that can install IPAs permanent...</td>\n",
       "      <td>C</td>\n",
       "      <td>77</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>opa334 /</td>\n",
       "      <td>JSON for Modern C++</td>\n",
       "      <td>C++</td>\n",
       "      <td>744</td>\n",
       "      <td>11,731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nlohmann /</td>\n",
       "      <td>Build ChatGPT over your data, all with natural...</td>\n",
       "      <td>Python</td>\n",
       "      <td>6,384</td>\n",
       "      <td>37,730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>run-llama /</td>\n",
       "      <td>🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。</td>\n",
       "      <td>Go</td>\n",
       "      <td>459</td>\n",
       "      <td>4,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1Panel-dev /</td>\n",
       "      <td>gRPC to JSON proxy generator following the gRP...</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>1,386</td>\n",
       "      <td>13,434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vaibhavs10 /</td>\n",
       "      <td>分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...</td>\n",
       "      <td>Go</td>\n",
       "      <td>174</td>\n",
       "      <td>2,765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grpc-ecosystem /</td>\n",
       "      <td>A PHP client library for accessing Google APIs</td>\n",
       "      <td>Python</td>\n",
       "      <td>2,112</td>\n",
       "      <td>16,522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>521xueweihan /</td>\n",
       "      <td>Ongoing research training transformer models a...</td>\n",
       "      <td>PHP</td>\n",
       "      <td>9,443</td>\n",
       "      <td>78,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>googleapis /</td>\n",
       "      <td>IP Toolkit. It allows you to view local IP, IP...</td>\n",
       "      <td>Python</td>\n",
       "      <td>3,655</td>\n",
       "      <td>8,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ftindy /</td>\n",
       "      <td>A Collection of application ideas which can be...</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>119</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NVIDIA /</td>\n",
       "      <td>Comprehensive Python Cheatsheet</td>\n",
       "      <td>Python</td>\n",
       "      <td>1,542</td>\n",
       "      <td>6,962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jason5ng32 /</td>\n",
       "      <td>🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>85</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>florinpop17 /</td>\n",
       "      <td>declaration of genesis</td>\n",
       "      <td>Swift</td>\n",
       "      <td>8,955</td>\n",
       "      <td>69,717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gto76 /</td>\n",
       "      <td>A library for building applications in a consi...</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>6,239</td>\n",
       "      <td>34,046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>makeplane /</td>\n",
       "      <td>🚀 The easiest way to automate building and rel...</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>853</td>\n",
       "      <td>18,635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>atomone-hub /</td>\n",
       "      <td>🧠 Your supercharged Second Brain 🧠 Your person...</td>\n",
       "      <td>Bicep</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pointfreeco /</td>\n",
       "      <td>Azure Quickstart Templates</td>\n",
       "      <td>Go</td>\n",
       "      <td>1,122</td>\n",
       "      <td>10,150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fastlane /</td>\n",
       "      <td>Random fake data generator written in go</td>\n",
       "      <td>Java</td>\n",
       "      <td>5,653</td>\n",
       "      <td>37,797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name                                        Description  \\\n",
       "0       LouisShark /                    store all agent's system prompt   \n",
       "1        linexjlin /                             leaked prompts of GPTs   \n",
       "2      OthersideAI /  Jailed iOS app that can install IPAs permanent...   \n",
       "3           opa334 /                                JSON for Modern C++   \n",
       "4         nlohmann /  Build ChatGPT over your data, all with natural...   \n",
       "5        run-llama /                     🔥 🔥 🔥 现代化、开源的 Linux 服务器运维管理面板。   \n",
       "6       1Panel-dev /  gRPC to JSON proxy generator following the gRP...   \n",
       "7       Vaibhavs10 /  分享 GitHub 上有趣、入门级的开源项目。Share interesting, entr...   \n",
       "8   grpc-ecosystem /     A PHP client library for accessing Google APIs   \n",
       "9     521xueweihan /  Ongoing research training transformer models a...   \n",
       "10      googleapis /  IP Toolkit. It allows you to view local IP, IP...   \n",
       "11          Ftindy /  A Collection of application ideas which can be...   \n",
       "12          NVIDIA /                    Comprehensive Python Cheatsheet   \n",
       "13      jason5ng32 /  🔥 🔥 🔥 Open Source JIRA, Linear and Height Alte...   \n",
       "14     florinpop17 /                             declaration of genesis   \n",
       "15           gto76 /  A library for building applications in a consi...   \n",
       "16       makeplane /  🚀 The easiest way to automate building and rel...   \n",
       "17     atomone-hub /  🧠 Your supercharged Second Brain 🧠 Your person...   \n",
       "18     pointfreeco /                         Azure Quickstart Templates   \n",
       "19        fastlane /           Random fake data generator written in go   \n",
       "\n",
       "            Language Conutrybuted Muted_Star  \n",
       "0                  C          549      3,110  \n",
       "1             Python        1,017      5,236  \n",
       "2                  C           77        925  \n",
       "3                C++          744     11,731  \n",
       "4             Python        6,384     37,730  \n",
       "5                 Go          459      4,190  \n",
       "6   Jupyter Notebook        1,386     13,434  \n",
       "7                 Go          174      2,765  \n",
       "8             Python        2,112     16,522  \n",
       "9                PHP        9,443     78,610  \n",
       "10            Python        3,655      8,903  \n",
       "11        JavaScript          119        770  \n",
       "12            Python        1,542      6,962  \n",
       "13        TypeScript           85        639  \n",
       "14             Swift        8,955     69,717  \n",
       "15              Ruby        6,239     34,046  \n",
       "16        TypeScript          853     18,635  \n",
       "17             Bicep           16         44  \n",
       "18                Go        1,122     10,150  \n",
       "19              Java        5,653     37,797  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trending_Repository=pd.DataFrame([])\n",
    "Trending_Repository['Name']=Repository_Name[:20]\n",
    "Trending_Repository['Description']=Description[:20]\n",
    "Trending_Repository['Language']=Language[:20]\n",
    "Trending_Repository['Conutrybuted']=Muted[:20]\n",
    "Trending_Repository['Muted_Star']=Muted_Star[:20]\n",
    "Trending_Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d8253d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18b806",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "57750a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "994e0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/charts/hot-100/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b7aa94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrap all tags\n",
    "\n",
    "Name=[]\n",
    "Name.append(driver.find_element(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\").text)\n",
    "Artist=[]\n",
    "Artist.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "221f3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nameTag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Name.extend([i.text for i in nameTag])\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist.extend([i.text for i in artistTag])\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d6c40cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "deee4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "90d055d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 133, 133, 133)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Name),len(Artist),len(lastweekpos),len(peakPos),len(weeksonBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "26b8f69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovin On Me</td>\n",
       "      <td>Jack Harlow</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Different 'Round Here</td>\n",
       "      <td>Riley Green Featuring Luke Combs</td>\n",
       "      <td>67</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bongos</td>\n",
       "      <td>Cardi B &amp; Megan Thee Stallion</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>But I Got A Beer In My Hand</td>\n",
       "      <td>Luke Bryan</td>\n",
       "      <td>75</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Calling For You</td>\n",
       "      <td>Drake Featuring 21 Savage</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mi Ex Tenia Razon</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>-</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SongName                        ArtistName  \\\n",
       "0                       Lovin On Me                       Jack Harlow   \n",
       "1                      Cruel Summer                      Taylor Swift   \n",
       "2                Paint The Town Red                          Doja Cat   \n",
       "3   All I Want For Christmas Is You                      Mariah Carey   \n",
       "4                            Snooze                               SZA   \n",
       "..                              ...                               ...   \n",
       "95            Different 'Round Here  Riley Green Featuring Luke Combs   \n",
       "96                           Bongos     Cardi B & Megan Thee Stallion   \n",
       "97      But I Got A Beer In My Hand                        Luke Bryan   \n",
       "98                  Calling For You         Drake Featuring 21 Savage   \n",
       "99                Mi Ex Tenia Razon                           Karol G   \n",
       "\n",
       "   Last Week PeekPosition Weeks On board  \n",
       "0          2            1              2  \n",
       "1          1            1             29  \n",
       "2          3            1             16  \n",
       "3         17            1             60  \n",
       "4          4            2             50  \n",
       "..       ...          ...            ...  \n",
       "95        67           20              6  \n",
       "96                                        \n",
       "97        75           61              8  \n",
       "98                                        \n",
       "99         -           84              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df['SongName']=Name\n",
    "df['ArtistName']=Artist\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b8a172d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0d38c",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb9ada19",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "55b6d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6073276",
   "metadata": {},
   "outputs": [],
   "source": [
    "book=[]\n",
    "author=[]\n",
    "volume=[]\n",
    "pub=[]\n",
    "genre=[]\n",
    "for j in range(1,101):\n",
    "    for i in driver.find_elements(By.XPATH,\"//tbody/tr[{}]/td[2]\".format(j)):\n",
    "        book.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,\"//tbody/tr[{}]/td[3]\".format(j)):\n",
    "        author.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,\"//tbody/tr[{}]/td[4]\".format(j)):\n",
    "        volume.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,\"//tbody/tr[{}]/td[5]\".format(j)):\n",
    "        pub.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,\"//tbody/tr[{}]/td[6]\".format(j)):\n",
    "        genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "052070df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Book Name':book,'Author Name':author,'Volume Sold':volume,'Publisher':pub,'Genre':genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc4c2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4addad7",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd6efbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e815d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d0bc5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Time=[]\n",
    "Rating=[]\n",
    "Votes=[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item mode-detail']/div[2]/h3/a\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchAttributeException as e:\n",
    "    Name.append('--')\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "        Year.append(i.text)  \n",
    "except NoSuchAttributeException as e:\n",
    "     Year.append('--')\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small']/span[5]\"):\n",
    "        Genre.append(i.text)  \n",
    "except NoSuchAttributeException as e:\n",
    "    Genre.append('--')\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//p[@class='text-muted text-small']/span[3]\"):\n",
    "        Time.append(i.text)  \n",
    "except NoSuchAttributeException as e:\n",
    "    Time.append('--')  \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-widget']/div/span[2]\"):\n",
    "        Rating.append(i.text)  \n",
    "except NoSuchAttributeException as e:\n",
    "    Rating.append('--')   \n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//span[@name='nv']\"):\n",
    "        Votes.append(i.text)  \n",
    "except NoSuchAttributeException as e:\n",
    "    Votes.append('--') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3885d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Time_Span</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>4,189 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,226,486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,293,463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,056,206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>310,108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>269,228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>213,156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>278,003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name         Year                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    Time_Span Rating      Votes  \n",
       "0   4,189 min    9.2  2,226,486  \n",
       "1      51 min    8.7  1,293,463  \n",
       "2      44 min    8.1  1,056,206  \n",
       "3      60 min    7.5    310,108  \n",
       "4      43 min    7.6    269,228  \n",
       "..        ...    ...        ...  \n",
       "95     42 min    7.5     53,273  \n",
       "96     50 min    7.8     65,355  \n",
       "97     42 min    8.1    213,156  \n",
       "98     45 min      7     44,371  \n",
       "99    572 min    8.6    278,003  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Name':Name,'Year':Year,'Genre':Genre,'Time_Span':Time,'Rating':Rating,'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5e347933",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851df07b",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "a5496333",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "848cd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "76665ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Name=[]\n",
    "Data_Type=[]\n",
    "Task=[]\n",
    "Attribute_Type=[]\n",
    "No_of_Instances=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "37e83517",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_1 = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')       # Locating page for top videos by xpath\n",
    "search_1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "5c812bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_2 = driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]/div[2]/span[2]')       # Locating page for top videos by xpath\n",
    "search_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "adb5048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Iris']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Dataset_Name \n",
    "dname=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div/div[2]/h2/a\")\n",
    "for i in dname:\n",
    "    if i.text is None :\n",
    "        Dataset_Name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_Name.append(i.text)\n",
    "print(len(Dataset_Name),Dataset_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9c8efc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Biology']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Data_Type \n",
    "dtype=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[2]/div/table/tbody/tr/td[1]')\n",
    "for i in dtype:\n",
    "    if i.text is None :\n",
    "        Data_Type.append(\"--\") \n",
    "    else:\n",
    "        Data_Type.append(i.text)\n",
    "print(len(Data_Type),Data_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "dc56cc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Classification']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Task \n",
    "t=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[1]/div[2]/div/div[1]/span')\n",
    "for i in t:\n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "print(len(Task),Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "b91d4705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['Real']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Attribute_Type \n",
    "att=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[2]/div/table/tbody/tr/td[2]')\n",
    "for i in att:\n",
    "    if i.text is None :\n",
    "        Attribute_Type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_Type.append(i.text)\n",
    "print(len(Attribute_Type),Attribute_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "60d25a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['150 Instances']\n"
     ]
    }
   ],
   "source": [
    "#scraping the No_of_Instances \n",
    "noi=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[1]/div[2]/div/div[3]/span\")\n",
    "for i in noi:\n",
    "    if i.text is None :\n",
    "        No_of_Instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_Instances.append(i.text)\n",
    "print(len(No_of_Instances),No_of_Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "53869864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['4 Features']\n"
     ]
    }
   ],
   "source": [
    "#scraping the No_of_Attribute \n",
    "noa=driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[1]/div[2]/div/div[4]/span\")\n",
    "for i in noa:\n",
    "    if i.text is None :\n",
    "        No_of_Attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_Attribute.append(i.text)\n",
    "print(len(No_of_Attribute),No_of_Attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "4fc4194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['7/1/1988']\n"
     ]
    }
   ],
   "source": [
    "#scraping the Year \n",
    "y=driver.find_elements(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[2]/div/table/tbody/tr/td[3]')\n",
    "for i in y:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\") \n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "print(len(Year),Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "fe0227cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_Name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>No_of_Instances</th>\n",
       "      <th>No_of_Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150 Instances</td>\n",
       "      <td>4 Features</td>\n",
       "      <td>7/1/1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset_Name Data_Type            Task Attribute_Type No_of_Instances  \\\n",
       "0         Iris   Biology  Classification           Real   150 Instances   \n",
       "\n",
       "  No_of_Attribute      Year  \n",
       "0      4 Features  7/1/1988  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UCI=pd.DataFrame([])\n",
    "UCI['Dataset_Name']=Dataset_Name[:100]\n",
    "UCI['Data_Type']=Data_Type[:100]\n",
    "UCI['Task']=Task[:100]\n",
    "UCI['Attribute_Type']=Attribute_Type[:100]\n",
    "UCI['No_of_Instances']=No_of_Instances[:100]\n",
    "UCI['No_of_Attribute']=No_of_Attribute[:100]\n",
    "UCI['Year']=Year[:100]\n",
    "UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c18edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thankyou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
